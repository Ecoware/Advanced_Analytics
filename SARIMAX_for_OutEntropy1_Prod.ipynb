{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'swe03'\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as pplt\n",
    "\n",
    "from decimal import *\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "from statsmodels.graphics.api import qqplot\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "desired_width = 400\n",
    "pd.set_option('display.width',desired_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm  \n",
    "import statsmodels.tsa as tsa\n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "#!pip install pandasql\n",
    "from pandasql import PandaSQL \n",
    "pdsql = PandaSQL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the Dataframe created from the Iterate-and-Create code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ent_calc_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Copied this from Iterate and Create for Out Entropy but was not used(i.e., commented out in the program).  \n",
    "\n",
    "ent_calc_df1.reset_index(inplace=True)\n",
    "#ent_calc_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ent_calc_df1['flStDttmEst'] = pd.to_datetime(ent_calc_df1['flStDttmEst'] )\n",
    "#ent_calc_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create a new index that has the correct dtype='datetime64[ns]\n",
    "ent_calc_df1 = ent_calc_df1.set_index('flStDttmEst')\n",
    "ent_calc_df1.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ent_calc_df1.index\n",
    "#ent_calc_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Specify the SARIMAX model\n",
    "## Default for the CI is 95%.  Set in the Alpha parameter for conf_int function\n",
    "mod = sm.tsa.statespace.SARIMAX(ent_calc_df1['out_degree_entropy'], \n",
    "         order=(3,1,0), seasonal_order=(3,0,0,12))\n",
    "mod1 = sm.tsa.statespace.SARIMAX(ent_calc_df1['out_degree_entropy'], \n",
    "      order=(8,0,0), seasonal_order=(2,0,0,6))\n",
    "mod2 = sm.tsa.statespace.SARIMAX(ent_calc_df1['out_degree_entropy'], \n",
    "     trend='n', order=(1,0,0), seasonal_order=(2,0,0,24))\n",
    "results = mod.fit()\n",
    "### Probably need to write this out to the BI Data Model and NOT print it here.....\n",
    "##print(results.summary())                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to write out to BI Data Model some of what is below, for example, Post Model Goodness of Fit Assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = results.plot_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Check to see if Residuals are still correlated\n",
    "## Values are between 0 and 4.  Values close to 2: no Serial Correlation. Close to 0: Pos Corr. Close to 4: Neg Corr.\n",
    "sm.stats.durbin_watson(results.resid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Check to see if the distributionb of Residuals are Normally Distributed (i.e., This is undesirable)\n",
    "##If the p-val is very small, it means it is unlikely that the data came from a normal distribution\n",
    "resid1 = results.resid\n",
    "stats.normaltest(resid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graph the acf and pacf for the Residuals\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(resid1.values.squeeze(), lags=10, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(resid1, lags=10, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Box-Pierce Q statistic tests the Null Ho that *ALL* correlations up to Lag K are equal to Zero.  This is not the \n",
    "# same as the correlogram above.\n",
    "r,q,p = sm.tsa.acf(resid1.values.squeeze(), qstat=True)\n",
    "data = np.c_[range(1,41), r[1:], q, p]\n",
    "table = pd.DataFrame(data, columns=['lag', \"AC\", \"Q\", \"Prob(>Q)\"])\n",
    "print(table.set_index('lag'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction and Forecasting Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is just a SARIMAX Results Wrapper.  It collects the model parameters for later use.\n",
    "res = mod.filter(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "### In-sample prediction and out-of-sample forecasting\n",
    "\n",
    "### The predict function works the same as res.predict() except that exogenous variables can be \n",
    "###   included as a parameter in this function as well as more statistical functions in the predict object model \n",
    "###   like predicted_mean and predicted_results\n",
    "predict = res.get_prediction()\n",
    "predict.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "## Create the Confidence Intervals for the entire range\n",
    "## Note that using the full range will create initial C.I.'s that are large (i.e., not enough history for tighter C.I.'s)\n",
    "##   This is change the scale of the graph and is not useful for visualization below\n",
    "predict_ci = predict.conf_int()\n",
    "predict_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "## Create the Predicted Means for Graph #1 below\n",
    "## The Predicted Means are both In-Sample Predictions as well as Out-Of-Sample Forecast\n",
    "#predict_dy.predicted_mean.astype(int)\n",
    "predicted_mean_1 = predict.predicted_mean.loc['2017-06-20 15:55:00':'2017-06-20 16:00:00'] \n",
    "predicted_mean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create the Confidence Intervals for Graph #1 below\n",
    "### This is a constrained view based on dates and is used below in the graphing\n",
    "### Note:  The Start date must be the LAST Training Set data Hour\n",
    "predict = res.get_prediction(start='2017-06-20 15:55:00', end='2017-06-20 16:00:00')\n",
    "predict_ci_1 = predict.conf_int()\n",
    "predict_ci_1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
